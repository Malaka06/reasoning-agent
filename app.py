import os
import re
import base64
from pathlib import Path
from typing import Dict, Optional

import streamlit as st
import requests


# =========================
# Page config (premium minimal)
# =========================
st.set_page_config(
    page_title="Reasoning Agent â€” AimÃ©e",
    page_icon="ğŸ§ ",
    layout="wide",
)

# =========================
# Hugging Face Router config
# =========================
MODEL_ID_DEFAULT = "moonshotai/Kimi-K2-Instruct-0905"
HF_URL = "https://router.huggingface.co/v1/chat/completions"


def get_hf_token() -> str:
    """Get HF token from Streamlit secrets or env."""
    if "HF_API_TOKEN" in st.secrets:
        return st.secrets["HF_API_TOKEN"]
    token = os.getenv("HF_API_TOKEN", "")
    return token


def make_hf_headers() -> Dict[str, str]:
    token = get_hf_token()
    return {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
    }


# =========================
# Identity + Facts (strict)
# =========================
IDENTITY_FR = (
    "Je suis lâ€™assistant IA dâ€™AimÃ©e. Je simule sa maniÃ¨re de raisonner et de prendre des dÃ©cisions "
    "en analyse data, marketing et mÃ©tier. Je ne la remplace pas et je ne parle pas Ã  sa place."
)
IDENTITY_EN = (
    "Iâ€™m AimÃ©eâ€™s AI assistant. I simulate how she reasons and makes decisions across data, marketing, "
    "and business. I do not replace her and I do not speak on her behalf."
)

# âš ï¸ Mets ici des faits vrais. N'ajoute rien que tu ne veux pas afficher publiquement.
AIMEE_FACTS = """
Nom : AimÃ©e

Positionnement :
- Business Analyst / Data Analyst junior
- Interface entre data, marketing et mÃ©tier
- Objectif : aider Ã  la prise de dÃ©cision (KPIs, analyses, dashboards)

CompÃ©tences / outils (niveau honnÃªte) :
- Power BI
- Looker Studio
- Google Analytics (GA4)
- SQL (notions)
- Python (notions)

Points forts :
- Traduire un besoin mÃ©tier en indicateurs et analyses
- Construire des dashboards utiles (usage + dÃ©cisions)
- Travailler avec des donnÃ©es imparfaites sans bloquer le projet
- Communiquer clairement avec des profils non techniques

Recherche :
- Postes : Data Analyst / Business Analyst (junior)
"""

REFUSAL_FR = (
    "Cette information relÃ¨ve de la sphÃ¨re personnelle et nâ€™est pas dÃ©taillÃ©e ici. "
    "Je peux en revanche parler du parcours professionnel et de la faÃ§on de travailler dâ€™AimÃ©e."
)
REFUSAL_EN = (
    "That information belongs to AimÃ©eâ€™s private life and isnâ€™t shared here. "
    "I can however talk about her professional background and how she works."
)

AIMEE_STYLE = """
Style de raisonnement (Ã  simuler) :
- Clarifier lâ€™objectif mÃ©tier et la dÃ©cision attendue
- Reformuler un besoin flou en question mesurable
- Choisir des KPIs utiles (pas juste disponibles)
- Qualifier la qualitÃ© des donnÃ©es et les limites
- Proposer une approche pragmatique orientÃ©e impact
- Expliquer sans jargon inutile
"""

SYSTEM_PROMPT = f"""
You are AimÃ©eâ€™s professional AI assistant.

ABSOLUTE RULES:
- You are NOT AimÃ©e.
- You speak about AimÃ©e in third person ONLY.
- Never say "I am AimÃ©e" or write as if you are AimÃ©e.
- If asked "Who are you?" or "Qui es-tu?" answer ONLY with the identity sentence in the user's language.

ABOUT AIMÃ‰E (single source of truth):
{AIMEE_FACTS}

AIMÃ‰E'S REASONING STYLE:
{AIMEE_STYLE}

TRUTHFULNESS (STRICT):
- Use ONLY the info above for questions ABOUT AimÃ©e.
- Never invent employers, dates, projects, countries, hobbies, private life details.
- If the info is not in the facts: say itâ€™s not specified.
- For private/sensitive topics: use the refusal sentence in the user language.

MANDATORY RESPONSE FORMAT:
Answer:
(1â€“2 sentences, decision-oriented)

Reasoning:
- step 1: clarify / diagnose
- step 2: analysis / trade-offs
- step 3: conclusion

Evidence:
- 2â€“3 concrete criteria / signals used

Alternatives:
- option 1 + why rejected
- option 2 + why rejected

Business conclusion:
- next concrete action / recommendation
""".strip()


# =========================
# Helpers
# =========================
def is_english(text: str) -> bool:
    t = (text or "").lower()
    return any(x in t for x in ["why", "what", "how", "who", "resume", "cv", "your", "you "])


def is_identity_question(text: str) -> bool:
    t = (text or "").lower()
    triggers = [
        "qui es-tu", "tu es qui", "câ€™est qui", "c'est qui",
        "who are you", "about you", "are you aimee", "are you aimÃ©e",
        "es-tu aimÃ©e", "Ãªtes-vous aimÃ©e", "agent", "assistant",
    ]
    return any(k in t for k in triggers)


def identity_answer(lang_en: bool) -> str:
    return IDENTITY_EN if lang_en else IDENTITY_FR


def refusal_answer(lang_en: bool) -> str:
    return REFUSAL_EN if lang_en else REFUSAL_FR


def call_llm(user_question: str, model_id: str) -> str:
    token = get_hf_token()
    if not token:
        raise RuntimeError("HF_API_TOKEN manquant. Ajoute-le dans Settings > Secrets (Streamlit) ou en variable dâ€™environnement.")

    payload = {
        "model": model_id,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_question},
        ],
        "temperature": 0.4,
    }

    r = requests.post(HF_URL, headers=make_hf_headers(), json=payload, timeout=90)
    if r.status_code != 200:
        raise RuntimeError(f"{r.status_code} - {r.text}")

    data = r.json()
    return data["choices"][0]["message"]["content"]


def split_sections(text: str) -> Dict[str, str]:
    """Split output into sections for clean UI. FR/EN supported."""
    if not text:
        return {"raw": ""}

    t = text.replace("\r\n", "\n")

    patterns = {
        "answer": r"(?im)^(rÃ©ponse|answer)\s*:\s*$",
        "reasoning": r"(?im)^(raisonnement|reasoning)\s*:\s*$",
        "evidence": r"(?im)^(preuves|evidence)\s*:\s*$",
        "alternatives": r"(?im)^(alternatives)\s*:\s*$",
        "conclusion": r"(?im)^(conclusion mÃ©tier|business conclusion)\s*:\s*$",
    }

    matches = []
    for key, pat in patterns.items():
        for m in re.finditer(pat, t):
            matches.append((m.start(), m.end(), key))
    matches.sort(key=lambda x: x[0])

    if not matches:
        return {"raw": text}

    out: Dict[str, str] = {}
    for i, (start, end, key) in enumerate(matches):
        next_start = matches[i + 1][0] if i + 1 < len(matches) else len(t)
        out[key] = t[end:next_start].strip()

    out["raw"] = text
    return out


def read_file_bytes(path: str) -> Optional[bytes]:
    p = Path(path)
    if p.exists() and p.is_file():
        return p.read_bytes()
    return None


def pdf_iframe(pdf_bytes: bytes, height: int = 820) -> None:
    b64 = base64.b64encode(pdf_bytes).decode("utf-8")
    st.components.v1.html(
        f"""
        <iframe
          src="data:application/pdf;base64,{b64}"
          width="100%"
          height="{height}px"
          style="border:0; border-radius:12px;"
        ></iframe>
        """,
        height=height + 20,
    )


# =========================
# UI â€” Header
# =========================
left, right = st.columns([2, 1], vertical_alignment="top")

with left:
    st.title("ğŸ§  Reasoning Agent â€” AimÃ©e")
    st.caption("Business Analyst / Data Analyst (junior) â€” Marketing Ã— Data Ã— MÃ©tier")

with right:
    st.markdown("#### ğŸ¯ Objectif")
    st.write("Montrer **comment AimÃ©e raisonne** et arbitre entre plusieurs options.")
    st.write("â¡ï¸ Câ€™est un assistant, pas une automatisation Ã  sa place.")

st.divider()

# =========================
# 3 pages
# =========================
tab_agent, tab_projects, tab_cv = st.tabs(["ğŸ§  Agent", "ğŸ“ Projets (mÃ©moire)", "ğŸ“„ CV"])


# =========================
# Page 1 â€” Agent
# =========================
with tab_agent:
    st.info("ğŸ‘‹ Recruteurs : posez une question. Lâ€™agent rÃ©pond de faÃ§on structurÃ©e (rÃ©ponse, raisonnement, preuves, alternatives).")

    examples = [
        "Qui es-tu ?",
        "Qui est AimÃ©e ?",
        "Pourquoi recruter AimÃ©e ?",
        "Comment traduirais-tu un besoin mÃ©tier flou en analyse data ?",
        "Que fais-tu si les donnÃ©es sont de mauvaise qualitÃ© ?",
        "Comment choisir des KPIs utiles pour piloter une campagne marketing ?",
        "How would you handle imperfect data under a tight deadline?",
    ]

    c1, c2 = st.columns([1, 2], vertical_alignment="top")
    with c1:
        selected = st.radio("ğŸ’¡ Exemples", examples, index=2)
        st.caption("Ou Ã©cris ta propre question.")
    with c2:
        question = st.text_area("Ta question", value=selected, height=140)

    with st.expander("âš™ï¸ ParamÃ¨tres (optionnel)"):
        model_id = st.text_input("Model", value=MODEL_ID_DEFAULT)
        st.caption("Tu peux laisser par dÃ©faut.")

    generate = st.button("ğŸš€ GÃ©nÃ©rer", use_container_width=True)

    if generate:
        if not question.strip():
            st.warning("Merci dâ€™Ã©crire une question.")
            st.stop()

        lang_en = is_english(question)

        # 1) Identity guard (no API call)
        if is_identity_question(question):
            st.markdown("### âœ… RÃ©ponse")
            st.write(identity_answer(lang_en))
            st.stop()

        # 2) LLM call
        with st.spinner("Analyse et raisonnement en coursâ€¦"):
            try:
                answer = call_llm(question, model_id=model_id)
            except Exception as e:
                st.error(f"Erreur IA : {e}")
                st.stop()

        sections = split_sections(answer)

        st.markdown("### ğŸ“Œ RÃ©sultat")
        st.markdown("#### âœ… RÃ©ponse")
        st.write(sections.get("answer", "â€”"))

        with st.expander("ğŸ§  Raisonnement", expanded=True):
            st.write(sections.get("reasoning", "â€”"))

        with st.expander("ğŸ“Œ Preuves / critÃ¨res", expanded=True):
            st.write(sections.get("evidence", "â€”"))

        with st.expander("ğŸ” Alternatives", expanded=False):
            st.write(sections.get("alternatives", "â€”"))

        with st.expander("ğŸ¯ Conclusion mÃ©tier (prochaine action)", expanded=True):
            st.write(sections.get("conclusion", "â€”"))

        # fallback if model ignored formatting
        if set(sections.keys()) == {"raw"}:
            st.divider()
            st.caption("Format brut :")
            st.markdown(sections["raw"])


# =========================
# Page 2 â€” Projets (incl. mÃ©moire)
# =========================
with tab_projects:
    st.subheader("ğŸ“ Projets & MÃ©moire")
    st.caption("Lâ€™objectif : montrer la valeur (objectif â†’ mÃ©thode â†’ rÃ©sultat), pas empiler des lignes.")

    st.markdown("### ğŸ“ Travail de fin dâ€™Ã©tude (MÃ©moire / TFE)")
    st.info("Conseil : une prÃ©sentation courte et claire. Le recruteur doit comprendre en 30 secondes.")

    # âœ… Remplace le contenu entre [...] par le tien
    st.markdown("""
**ProblÃ©matique**  
[1â€“2 phrases : problÃ¨me mÃ©tier + dÃ©cision attendue]

**Contexte**  
- Secteur : [...]
- Enjeu business : [...]
- Contraintes : [...]

**DonnÃ©es**  
- Sources : [...]
- PÃ©rimÃ¨tre : [...]
- QualitÃ© : [...]

**Approche**  
- Cadrage + KPIs  
- Analyse exploratoire  
- ModÃ©lisation / scoring (si applicable)  
- InterprÃ©tation / restitution

**RÃ©sultats clÃ©s**  
- [...]
- [...]
- [...]

**Limites**  
- [...]
- [...]

**Livrables**  
- Dashboard / rapport / application : [...]
""")

    st.divider()

    st.markdown("### ğŸ§© Projets (sÃ©lection)")
    st.caption("2â€“3 projets forts max.")

    for title in ["Projet 1 â€” Dashboard Power BI", "Projet 2 â€” Analyse marketing (GA4/Looker)", "Projet 3 â€” (optionnel)"]:
        with st.expander(f"ğŸ“Œ {title}", expanded=(title == "Projet 1 â€” Dashboard Power BI")):
            st.markdown("""
**Objectif** : [...]  
**DonnÃ©es** : [...]  
**Ce que jâ€™ai fait** : [...]  
**RÃ©sultat / impact** : [...]  
**Livrables** : dashboard + synthÃ¨se dÃ©cisionnelle  
**Lien (optionnel)** : [...]
""")

    st.divider()

    st.markdown("### ğŸ“¸ Dashboards (captures)")
    st.caption("Ajoute 2â€“4 captures dans `assets/` et affiche-les ici.")

    # Exemple: dÃ©commente et renomme tes fichiers
    # st.image("assets/dashboard_1.png", caption="Dashboard â€” KPIs marketing", use_container_width=True)
    # st.image("assets/dashboard_2.png", caption="Dashboard â€” Suivi business", use_container_width=True)


# =========================
# Page 3 â€” CV
# =========================
with tab_cv:
    st.subheader("ğŸ“„ CV")
    st.caption("Le CV est disponible au tÃ©lÃ©chargement et en aperÃ§u.")

    st.markdown("#### â¬‡ï¸ TÃ©lÃ©charger le CV")
    st.write("Place ton CV dans le repo : `assets/cv.pdf` (recommandÃ©).")

    cv_bytes = read_file_bytes("assets/cv.pdf")

    if cv_bytes:
        st.download_button(
            label="TÃ©lÃ©charger le CV (PDF)",
            data=cv_bytes,
            file_name="CV_Aimee.pdf",
            mime="application/pdf",
            use_container_width=True,
        )

        st.markdown("#### ğŸ‘€ AperÃ§u")
        pdf_iframe(cv_bytes, height=820)
    else:
        st.warning("Je ne trouve pas `assets/cv.pdf`. Ajoute-le puis redeploie.")

st.divider()
st.caption("ğŸ§  Reasoning Agent â€” AimÃ©e | Candidature : Business Analyst / Data Analyst (junior)")
